{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ad28cd",
   "metadata": {},
   "source": [
    "# MyoSDK Tutorial\n",
    "\n",
    "## What is MyoSDK?\n",
    "\n",
    "MyoSapiens SDK (MyoSDK) is a Python library that allows you to **Retarget motion** from marker datas onto a 3D character.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "This tutorial will walk you through the complete process:\n",
    "1. Setting up the MyoSDK client\n",
    "2. Apply marker data describing a motion to a 3D character (retargeting)\n",
    "3. Downloading the final animated character file\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, make sure you have:\n",
    "- **Python 3.8 or higher** installed\n",
    "- **An API key** from MyoLab (you'll need to sign up and get your API key)\n",
    "- **A Mocap file in c3d format** showing a person moving\n",
    "- **A Markerset file** describing approximately where the markers are placed on the body\n",
    "- **Basic Python knowledge** (understanding variables, functions, and basic syntax)\n",
    "\n",
    "## Installation\n",
    "\n",
    "If you haven't installed `myosdk` yet, run this command in your terminal:\n",
    "```bash\n",
    "pip install myosdk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required libraries\n",
    "import os\n",
    "import myosdk\n",
    "from myosdk import Client\n",
    "# Step 2: Set up your API key\n",
    "# The API key is like a password that authenticates you with the MyoSDK service.\n",
    "# You can get your API key from your MyoLab account dashboard at dev.myolab.ai.\n",
    "# Instructions are available at https://docs.myolab.ai/docs/myosdk/getting-started/api-key\n",
    "\n",
    "# Option 1 (Recommended): Set it as an environment variable\n",
    "# In your terminal, run: export MYOSDK_API_KEY=\"your-api-key-here\"\n",
    "# Or on Windows: set MYOSDK_API_KEY=your-api-key-here\n",
    "\n",
    "# Option 2: Replace \"...\" below with your actual API key (less secure, but easier for testing)\n",
    "api_key = os.getenv(\"MYOSDK_API_KEY\", \"...\")\n",
    "\n",
    "# Step 3: Create the client\n",
    "# The client is your connection to the MyoSDK service. It handles all communication\n",
    "# with the servers. The base_url tells it which server to connect to.\n",
    "client = Client(api_key=api_key)\n",
    "\n",
    "# Verify the connection worked\n",
    "print(\"Client initialized successfully.\")\n",
    "print(f\"âœ“ You're ready to use MyoSDK version {myosdk.__version__}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2c8b1",
   "metadata": {},
   "source": [
    "## 1. Process video and upload Input Assets\n",
    "\n",
    "We need to process a video. We used Metrabs, a non-commercial OSS video to motion library, to produce 3d trackers. This and the corresponding markerset files are then upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fd7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrabs_pytorch.scripts.run_video import run_metrabs_video\n",
    "from myo_tools.mjs.marker.marker_api import get_marker_names\n",
    "from myo_tools.utils.file_ops.dataframe_utils import from_array_to_dataframe\n",
    "import torch\n",
    "import numpy as np\n",
    "from myo_tools.utils.mocap_ops.mocap_utils import rotate_mocap_ydown_to_zup\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "video_path = \"../data/13710671_1080_1920_25fps.mp4\"\n",
    "results = list(\n",
    "            run_metrabs_video(video_path=video_path, device=DEVICE, visualize=False)\n",
    "        )\n",
    "\n",
    "# trackers from videos are in opencv space i.e. y-up, and we need in z-up space\n",
    "markers = rotate_mocap_ydown_to_zup(np.array([res[\"poses3d\"] for res in results]).squeeze())\n",
    "\n",
    "fps = results[0][\"fps\"]\n",
    "\n",
    "markerset_path = \"../markersets/movi_metrabs_markerset.xml\"\n",
    "\n",
    "# Upload trackers file\n",
    "marker_names = get_marker_names(markerset_path)\n",
    "fn_parquet = \"video_trackers.parquet\"\n",
    "from_array_to_dataframe(markers, marker_names, fps, fn_parquet)\n",
    "tracker_asset = client.assets.upload_file(fn_parquet, purpose=\"retarget\")\n",
    "\n",
    "print(tracker_asset)\n",
    "\n",
    "# Upload markerset XML file\n",
    "markerset_asset = client.assets.upload_file(markerset_path)\n",
    "print(markerset_asset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6109d0",
   "metadata": {},
   "source": [
    "## 2. Motion Retargeting\n",
    "\n",
    "Use the extracted motion data (trackers) to retarget onto a 3D character. This is called \"retargeting.\"\n",
    "\n",
    "**What is retargeting?** Think of it like this: you recorded someone dancing, extracted their dance moves, and now you're applying those exact same moves to a 3D character. The character will move in the same way as the person in your video.\n",
    "\n",
    "**What you need:**\n",
    "- The `tracker_asset` describing the motion data\n",
    "- The `markerset_asset` describing the association of motion data to body parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start retargeting job\n",
    "job = client.jobs.start_retarget(\n",
    "    tracker_asset_id=tracker_asset[\"asset_id\"],\n",
    "    markerset_asset_id=markerset_asset[\"asset_id\"],\n",
    ")\n",
    "\n",
    "# Wait for job to complete\n",
    "result = client.jobs.wait(job[\"job_id\"])\n",
    "asset_ids = result[\"output\"][\"retarget_output_asset_ids\"]\n",
    "print(asset_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16e978",
   "metadata": {},
   "source": [
    "## 3. Download Result\n",
    "\n",
    "Finally, we'll download the joint angles.\n",
    "\n",
    "**Note:** Make sure the output directory exists, or the download will create it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parquet_path = \"tmp-assets/tutorial_output.parquet\"\n",
    "\n",
    "print(f\"Downloading motion joint angles result to {output_parquet_path}...\")\n",
    "os.makedirs(os.path.dirname(output_parquet_path), exist_ok=True)\n",
    "client.assets.download(asset_ids[\"qpos\"], output_parquet_path)\n",
    "\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myo_tools.utils.file_ops.io_utils import from_qpos_to_joint_angles\n",
    "# Reads a dataframe with qpos and converts it to joint angles\n",
    "data = from_qpos_to_joint_angles(output_parquet_path)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myo_sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
